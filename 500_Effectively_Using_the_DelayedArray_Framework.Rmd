```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
    comment = "#>",
    collapse = TRUE,
    cache = TRUE
)
```
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
    comment = "#>",
    collapse = TRUE,
    cache = TRUE
)
```
---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Effectively using the DelayedArray framework to support the analysis of large datasets

Authors:
    Peter Francis Hickey^[Department of Biostatistics, Johns Hopkins University],
    <br/>
Last modified: 12 June, 2018.

## Overview

### Description

This workshop will teach the fundamental concepts underlying the DelayedArray framework and related infrastructure. 
It is intended for package developers who want to learn how to use the DelayedArray framework to support the analysis of large datasets, particularly through the use of on-disk data storage.

The first part of the workshop will provide an overview of the DelayedArray infrastructure and introduce computing on DelayedArray objects using delayed operations and block-processing.
The second part of the workshop will present strategies for adding support for DelayedArray to an existing package and extending the DelayedArray framework.

Students can expect a mixture of lecture and question-and-answer session to teach the fundamental concepts.
There will be plenty of examples to illustrate common design patterns for writing performant code, although we will not be writing much code during the workshop.

### Pre-requisites

* Solid understanding of R
* Familiarity with common operations on arrays (e.g., `colSums()` and those available in the **matrixStats** package)
* Familiarity with object oriented programming, particularly S4, will be useful but is not essential
* No familiarity required of technical details of particular data storage backends (e.g., HDF5, sparse matrices)
* No familiarity required of particular biological techniques (e.g., single-cell RNA-seq)

### Participation

Questions and discussion are encouraged! 
This will be especially important to guide the second half of the worshop which focuses on integrating DelayedArray into an existing or new Bioconductor package.
Students will be expected to be able to follow and reason about example R code. 

### _R_ / _Bioconductor_ packages used

* DelayedArray
* HDF5Array
* SummarizedExperiment
* DelayedMatrixStats
* beachmat

### Time outline

| Activity                                          | Time |
|---------------------------------------------------|------|
| Introductory slides                               | 15m  |
| Part 1: Overview of DelayedArray framework        | 45m  |
| Part 2: Incoporating DelayedArray into a package  | 45m  |
| Questions and discussion                          | 15m  |

### Workshop goals and objectives

#### Learning goals

* Identify when it is useful to use a *DelayedArray* instead of an ordinary array or other array-like data structure.
* Become familiar with the fundamental concepts of delayed operations, block-processing, and realization.
* Learn of existing functions and packages for constructing and computing on DelayedArray objects, avoiding the need to re-invent the wheel.
* Learn common design patterns for writing performant code that operates on a DelayedArray.
* Evaluate whether an existing function that operates on an ordinary array can be readily adapted to work on a DelayedArray.
* Reason about potential bottlenecks in algorithms operating on DelayedArray objects.

#### Learning objectives

* Understand the differences between a *DelayedArray* instance and an instance of a subclass (e.g., *HDF5Array*, *RleArray*).
* Know what types of operations 'degrade' an instance of a *DelayedArray* subclass to a *DelayedArray*, as well as when and why this matters.
* Construct a *DelayedArray*:
  * From an in-memory array-like object.
  * From an on-disk data store (e.g., HDF5).
  * From scratch by writing data to a *RealizationSink*.
* Take a function that operates on rows or columns of a matrix and apply it to a DelayedMatrix.
* Use block-processing on a *DelayedArray* to compute:
  * A univariate (scalar) summary statistic (e.g., `max()`).
  * A multivariate (vector) summary statistic (e.g., `colSum()` or `rowMean()`).
  * A multivariate (array-like) summary statistic (e.g., `rowRanks()`).
* Design an algorithm that imports data into a DelayedArray.

## Introductory material

Data from a high-throughput biological assay, such as single-cell RNA-sequencing (scRNA-seq), will often be summarised as a matrix of counts, where rows correspond to features and columns to samples^[Higher-dimensional arrays may be appropriate for some types of assays.].
Within **Bioconductor**, the *SummarizedExperiment* class is the recommended container for such data, offering a rich interface that tightly links assay measurements to data on the features and the samples.

![The _SummarizedExperiment_ class is used to store rectangular arrays of experimental results (_assays_). Although each _assay_ is here drawn as a matrix, higher-dimensional arrays are also supported.](https://docs.google.com/feeds/download/drawings/Export?id=1kiC8Qlo1mhSnLDqkGiRNPSo6GWn3C2duBszCFbJCB-g&exportFormat=svg)

Traditionally, the assay data are stored in-memory as an ordinary *array* object^[In R, a *matrix* is just a 2-dimensional *array*]. 
Storing the data in-memory becomes a real pain with the ever-growing size of 'omics datasets; it is now not uncommon to collect $10,000-100,000,000$ measurements on $100 - 1,000,000$ samples, which would occupy $10-1,000$ gigabytes (GB) if stored in-memory as ordinary R arrays!

Let's take as an example some single-cell RNA-seq data on 1.3 million brain cells from embryonic mice, generated by 10X Genomics^[These data are available in the **TENxBrainData** Bioconductor package].

```{r}
library(TENxBrainData)
# NOTE: This will download the data and may take a little while on the first 
#       run. The result will be cached, however, so subsequent runs are near 
#       instantaneous.
tenx <- TENxBrainData()
# NOTE: The data are stored in a SingleCellExperiment, an extension of the 
#       SummarizedExperiment class.
class(tenx)
dim(tenx)

# How big much memory do the counts data use?
counts <- assay(tenx, "counts", withDimnames = FALSE)
print(object.size(counts))
```

The counts data only require a tiny amount of RAM despite it having `r nrow(tenx)` rows and `r ncol(tenx)` columns.
And the `counts` object still "feels" like an ordinary R matrix:


```{r}
# Oooh, pretty-printing.
counts
# Let's take a subset of the data
counts[1:10, 1:10]
# Let's compute column sums (crude library sizes) for the first 100 samples.
# TODO: DelayedArray:: prefix shouldn't be necessary
DelayedArray::colSums(counts[, 1:100])
```

The reason for the small memory footprint and matrix-like "feel" of the `counts` object is because the counts data are in fact stored on-disk in a Hierarchical Data Format (**HDF5**) file and we are interacting with the data via the DelayedArray framework.

### Discussion

**TODO:** Make these 'discussions/challenges' into a boxes that visually break out

- Talk with your neighbour about the sorts of 'big data' you are analysing, the challenges you've faced, and strategies you're using to tackle this.
- **TODO:** (keep this?) Play around with the `tenx` and `counts` data. Could use this to demonstrate the upcoming challenges of chunking (e.g., compute row-wise summary).

**TABLE** gives some examples of contemporary experiments and the memory requirements if these data are to be stored in-memory as ordinary R arrays.

```{r, echo = FALSE}
# TODO: Add WGBS (mCA)
# TODO: An example of an RleArray-type dataset (ChIP-seq)
x <- data.frame(
    Assay = c("scRNA-seq", "WGBS (mCG)"),
    Size = c(
        as.character(
            memuse::howbig(27998, 1306127, type = "integer", prefix = "SI")),
        as.character(
            2 * memuse::howbig(29307073, 145, type = "integer", prefix = "SI") + 
                memuse::howbig(29307073, 145, type = "double", prefix = "SI"))),
    "`nrow`" = c("27,998", "29,307,073"),
    "`ncol`" = c("1,306,127", "145"),
    "Number of assays" = c(1, 3),
    Type = c("sparse integer", "2 x dense integer, 1 x dense double"),
    Reference = c(
        "https://bioconductor.org/packages/TENxBrainData/", 
        "eGTEx (unpublished)"),
    check.names = FALSE,
    stringsAsFactors = FALSE)
# TODO: Manually update order to be increasing in x$Size
knitr::kable(x[2:1, ], row.names = FALSE)
```

There are various strategies for handling such large data in R. 
For example, we could use:

1. Sparse matrices for single-cell RNA-seq data.
2. Run length encoded vectors for ChIP-seq coverage profiles.
3. Storing data on disk, and only bringing into memory as required, for whole genome methylation data^[This strategy can also be effectively applied to sparse and repetitive data by using on-disk compression of the data.].

Each of these approaches has its strengths, as well as weaknesses and idiosyncrasies.
For example,

- **Matrix** doesn't support long vectors
- Sparsity is readily lost (e.g., normalization often destroys it)
- etc.

**TODO:** Lead discussion of limitations

### Why learn DelayedArray?

The high-level goals of the DelayedArray framework are:

- Provide a common R interface to array-like data, where the data may be in-memory or on-disk.
- Support delayed operations, which avoid doing any computation until the result is required.
- Support block-processing of the data, which enables bounded-memory and parallel computations.

From the **DelayedArray** `DESCRIPTION`:

**TODO:** Use **desc** to extract Description field?

> Wrapping an array-like object (typically an on-disk object) in a DelayedArray object allows one to perform common array operations on it without loading the object in memory. In order to reduce memory usage and optimize performance, operations on the object are either delayed or executed using a block processing mechanism. Note that this also works on in-memory array-like objects like DataFrame objects (typically with Rle columns), Matrix objects, and ordinary arrays and data frames. (https://bioconductor.org/packages/release/bioc/html/DelayedArray.html)

These goals are similar to that of the **tibble** and **dplyr** packages:

> A tibble, or `tbl_df`, is a modern reimagining of the data.frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are data.frames that are lazy and surly (http://tibble.tidyverse.org/#overview)

> dplyr is designed to abstract over how the data is stored. That means as well as working with local data frames, you can also work with remote database tables, using exactly the same R code. (https://dplyr.tidyverse.org/#overview)

An important feature of the DelayedArray framework is that it supports all these strategies, and more, with a common interface that aims to feel like the interface to ordinary arrays, which provides familiarity to R users.

#### Learning goal

- Identify when it is useful to use a *DelayedArray* instead of an ordinary array or other array-like data structure.

## Overview of DelayedArray framework

The core of DelayedArray framework is implemented in the **DelayedArray** Bioconductor package.
Other packages extend the framework or simply use it as is to enable analyses of large datasets.

### The **DelayedArray** package

The **DelayedArray** package defines the key classes, generics, and methods^[The **DelayedArray** package, like all core Bioconductor packages, uses the [S4 object oriented programming system.](http://adv-r.had.co.nz/OO-essentials.html#s4)], as well as miscellaneous helper functions, that implement the DelayedArray framework.

The reverse dependencies of **DelayedArray** are shown below:

```{r, echo = FALSE}
# TODO: This is a GitHub only package, 
#       `BiocManager::install("seandavi/BiocPkgTools")`
library(BiocPkgTools)
library(tidygraph)
library(ggraph)

`%>%` <- dplyr::`%>%`

# TODO: Re-write so as to avoid library() calls that clobbers the NAMESPACE
# NOTE: From http://lazappi.id.au/2018/06/exploring-the-sce-verse/
get_bioc_deps <- function(bpi, pkg, reverse) {
    deps <- bpi %>%
        dplyr::filter(Package == pkg)
    
    if (reverse) {
        deps <- deps %>%
            dplyr::select(depends = dependsOnMe, imports = importsMe,
                          suggests = suggestsMe)
    } else {
        deps <- deps %>%
            dplyr::select(depends = Depends, imports = Imports,
                          suggests = Suggests)
    }
    
    deps <- deps %>%
        tidyr::gather(key = "type", value = "package") %>%
        tidyr::separate_rows() %>%
        dplyr::filter(!is.na(package))
    
    if (reverse) {
        deps <- deps %>%
            dplyr::mutate(package2 = pkg) %>%
            dplyr::rename(package1 = package)
    } else {
        deps <- deps %>%
            dplyr::mutate(package1 = pkg) %>%
            dplyr::rename(package2 = package)
    }
    
    deps <- deps %>% dplyr::select(package1, uses = type, package2)
}
# NOTE: From http://lazappi.id.au/2018/06/exploring-the-sce-verse/
get_cran_deps <- function(pkg, db, reverse) {
    
    types <- c("Depends", "Imports", "Suggests")
    
    deps <- sapply(types, function(type) {
        deps <- tools::package_dependencies(pkg, db, which = type,
                                            reverse = reverse)
        c(type = type, package = paste(deps[[1]], collapse = ", "))
    })
    
    deps <- deps %>%
        t() %>%
        dplyr::as_data_frame() %>%
        dplyr::mutate(type = tolower(type)) %>%
        dplyr::filter(package != "") %>%
        tidyr::separate_rows(package)
    
    if (nrow(deps) == 0) {
        return(dplyr::tibble(package1 = character(), uses = character(),
                             package2 = character()))
    }
    
    if (reverse) {
        deps <- deps %>%
            dplyr::mutate(package2 = pkg) %>%
            dplyr::rename(package1 = package)
    } else {
        deps <- deps %>%
            dplyr::mutate(package1 = pkg) %>%
            dplyr::rename(package2 = package)
    }
    
    deps <- deps %>% dplyr::select(package1, uses = type, package2)
}

bpi <- getBiocPkgList()
db <- available.packages(repos = "http://cran.r-project.org")

bioc_revdeps <- get_bioc_deps(bpi, "DelayedArray", reverse = TRUE)
cran_revdeps <- get_cran_deps("DelayedArray", db, reverse = TRUE)

nodes <- bioc_revdeps %>%
    dplyr::bind_rows(cran_revdeps) %>%
    dplyr::select(-uses) %>%
    tidyr::gather(key = id, value = package) %>%
    dplyr::select(-id) %>%
    dplyr::distinct() %>%
    dplyr::mutate(
        repo = dplyr::if_else(package %in% bpi$Package, "Bioconductor", "CRAN"))

edges <- bioc_revdeps %>%
    dplyr::bind_rows(cran_revdeps) %>%
    dplyr::rename(from = package1, to = package2)

graph <- tbl_graph(nodes = nodes, edges = edges)

ggraph(graph, layout = "fr") +
    geom_edge_fan(aes(colour = uses),
                  arrow = arrow(length = unit(4, 'mm')), 
                  end_cap = circle(3, 'mm')) +
    geom_node_point(aes(colour = repo)) +
    geom_node_text(aes(label = package, colour = repo), repel = TRUE) +
    scale_color_brewer(palette = "Set1") +
    scale_edge_color_brewer(palette = "Dark2") +
    theme_graph()
```

The above figures includes packages that extend the DelayedArray framework in various ways, as well as those that simply use the DelayedArray framework to analyse specific types of 'omics data. We briefly discuss some of these:

### Packages that extend **DelayedArray**

There are two ways a package may extend the DelayedArray framework. 
The first kind of package adds support for a new _realization backend_ (**TODO** Define?). Examples of this are:

- The **HDF5Array** package adds the *HDF5Array* realization backend for accessing and creating data stored on-disk in an HDF5 file. This is typically used for on-disk representation of multidimensional (numeric) arrays.
- The **GDSArray** package adds the *GDSArray* backend for accessing and creating data stored on-disk in a GDS file. This is typically used for on-disk representation of genotyping or sequence data.
- The **rhdf5client** and **restfulSE** packages add the *H5S_Array* realization backend for accessing and creating data stored on a HDF Server, a Python-based web service that can be used to send and receive HDF5 data using an HTTP-based REST interface. This is typically used for on-disk representation of multidimensional (numeric) arrays that need to be shared with multiple users from a central location.

The second kind of package adds methods for computing on _DelayedArray_ instances. Examples of this are:

- The **DelayedMatrixStats** package provides methods for computing commonly used row- and column-wise summaries of a 2-dimensional *DelayedArray*.
- The **beachmat** package provides a consistent C++ class interface for a variety of commonly used matrix types, including ordinary R arrays, sparse matrices, and *DelayedArray* with various backends.
- The **kmknn** package provides methods for performing k-means for k-nearest neighbours of data stored in a *DelayedArray*.
- Packages for performing matrix factorizations, (generalized) linear regression, , etc. (work in progress)

### Packages that use **DelayedArray**

- The **bsseq** package uses the DelayedArray framework to support the analysis of large whole-genome bisulfite methylation sequencing experiments.
- **TODO**: minfi, scater, scran, others

### The **DelayedArray** class

The _DelayedArray_ class is the key object that users of the DelayedArray framework will interact with.

```{r}
# TODO: Graphical representation of this network?
# NOTE: Illustrate How classes depend on one another
#       a. with DelayedArray as the root
#       b. With DelayedArray as the leaf
showClass(getClass("DelayedArray", where = "DelayedArray"))
showClass(getClass("HDF5Array", where = "HDF5Array"))
```

As seen above, the *DelayedArray* class has a single slot called the *seed*. 
This name is evocative, it is the core of the object.
We'll explore four types of seeds: "simple" and "formal" in-memory seeds, on-disk seeds, and *DelayedOp* seeds^[The terms "simple" and "formal" aren't formally part of the DelayedArray framework, but I'll use them to illustrate some ideas in this workshop. On-disk seeds and *DelayedOp* seeds are always "formal".].
A "formal" seed defines an S4 class and methods that that conforms to the "seed contract", a minimal set of operations the seed must support.

The seed contract is the following^[See `vignette("02-Implementing_a_backend", "DelayedArray")` for details.]:

- `dim(x)`: Return the dimensions of the seed.
- `dimnames(x)`: Return the (possibly `NULL`) dimension names of the seed.
- `extract_array(x, index)`: Return a slice, specified by `index`, of the seed as an ordinary R *array*. Sometimes, this will "just work" with minimal developer effort.

#### "Simple" seeds

A "simple" seed is an instance of an existing "array-like" object. 
This object could be fundamental R structure, such as an *array*, or an existing S3 or S4 class.
These "just work" when passed to the `DelayedArray()` constructor^[This is because the **DelayedArray** package implements the seed contract for these existing classes without requiring yet another class].

To begin, we'll consider a *DelayedArray* instance with the simplest *seed*, an in-memory array:

```{r}
library(DelayedArray)

# An example using a fundamental R structure as the seed.
mat <- matrix(rep(1:20, 1:20), ncol = 2)
da_mat <- DelayedArray(seed = mat) 
da_mat
str(da_mat)
```

We can use other, more complex, array-like objects as the *seed*:

```{r}
# An example using another fundamental R structure as the seed.
df <- as.data.frame(mat)
da_df <- DelayedArray(seed = df)
# NOTE: This inherits the (default) column names of the data.frame.
da_df
str(da_df)

# An example using an S3 instance as the seed.
library(tibble)
tbl <- as_tibble(mat)
da_tbl <- DelayedArray(seed = tbl)
str(da_tbl)

# An example using an S4 instance as the seed.
library(Matrix)
Mat <- Matrix(mat)
da_Mat <- DelayedArray(seed = Mat)
# NOTE: The type is 'double' because of how the Matrix package stores the data.
da_Mat
str(da_Mat)
```

#### "Formal" seeds

The rest of the seeds that we'll look at are "formal" seeds that explicitly implement the seed contract in a new class and methods.

##### In-memory seeds

The **DelayedArray** package defines the *RleArray* class, a *DelayedArray* subclass containing run-length encoded data.
The *seed* of an *RleArray* is a *RleArraySeed* (either an instance of a *SolidRleArraySeed* or a *ChunkedRleArraySeed*).

```{r}
# NOTE: The DelayedArray package does not expose the RleArraySeed() constructor.
#       Instead, we directly call the RleArray() constructor.
da_Rle <- RleArray(rle = Rle(mat), dim = dim(mat))
da_Rle
str(da_Rle)
```

##### On-disk seeds

The **HDF5Array** package defines the *HDF5Array* class, a *DelayedArray* subclass for data stored on disk in a HDF5 file.
The *seed* of an *HDF5Array* is a *HDF5ArraySeed*.
It is important to note that creating a *HDF5Array* does not read the data into memory!
The data remain on disk until explicitly requested (we'll see how to do this later on in the workshop).

```{r}
library(HDF5Array)

# TODO: What path to use?
hdf5_file <- "hdf5_mat.h5"
# NOTE: We can use rhdf5::h5ls() to take a look what is in the HDF5 file.
rhdf5::h5ls(hdf5_file)
# NOTE: We first demonstrate how to create the HDF5Array explicitly by 
#       creating a HDF5ArraySeed and then creating the HDF5Array.
# 1. Create the HDF5ArraySeed.
hdf5_seed <- HDF5ArraySeed(filepath = hdf5_file, name = "hdf5_mat")
# 2. Create the HDF5Array
da_hdf5 <- DelayedArray(seed = hdf5_seed)
da_hdf5
# NOTE: Alternatively, we can create this in one go using the HDF5Array()       
#       constructor.    
da_hdf5 <- HDF5Array(hdf5_file, "hdf5_mat")
da_hdf5
str(da_hdf5)
```

##### *DelayedOp*

The final type of seed is a *DelayedOp*, used to 'record' delayed operations.
*DelayedOp* objects are not intended to be manipulated directly by the user but are used inside *DelayedArray* objects.
A 'delayed operation' is one that is not actually performed until the result is required.
Here's a simple example of a delayed operations: taking the negative of every element of a *HDF5Matrix*:

```{r}
da_hdf5
-da_hdf5
```

It may look like constructing  `-da_hdf5` has taken the negative of every value.
However, we can use the `showtree()` function to inspect the internal state of these objects and see this is not the case^[You may like to use the `str()` function for more detailed and verbose output]:

```{r}
showtree(da_hdf5)

# NOTE: See the "Unary iso op" line, below.
showtree(-da_hdf5)
```

Rather than modifying the data stored in the HDF5 file, which can be costly for large datasets, we've recorded the 'idea' of this operation as a *DelayedOp*.

In a *DelayedArray* object the delayed operations are stored as a tree of *DelayedOp* objects.
Each node in the tree is represented by a *DelayedOp* object, of which there are 6 concrete subclasses:

| Node type           | Out-degree | Operation                                                 |
|---------------------|------------|-----------------------------------------------------------|
| *DelayedSubset*     | 1          | Multi-dimensional single bracket subsetting               |
| *DelayedAperm*      | 1          | Extended `aperm()` (can drop dimensions)                  |
| *DelayedUnaryIsoOp* | 1          | Unary op that preserves the geometry (e.g., `-`, `log()`) |
| *DelayedDimnames*   | 1          | Set dimnames                                              |
| *DelayedNaryIsoOp*  | N          | N-ary op that preserves the geometry                      |
| *DelayedAbind*      | N          | `abind()`                                                 |                                            |

We'll discuss delayed operations more, shortly.

#### So what seed should I use?

Notably, `da_mat`, `da_Mat`, `da_tbl`, `da_df`, `da_Rle`, and `da_hdf5` all "look" and "feel" much the same.
The *DelayedArray* is a very light wrapper around the *seed* that formalises this consistent "look" and "feel".

**Key idea**: A *DelayedArray* is a lightweight wrapper around 

**TODO**: Provide guidance on how you should choose the *seed* of a *DelayedArray, e.g., memory-footprint, performance considerations, etc. Should this go here?

### Fundamental concepts

**TODO (UP TO HERE)**

#### Learning goals 

* Become familiar with the fundamental concepts of delayed operations, block-processing, and realization.

#### Learning objective

* Know what types of operations 'degrade' an instance of a *DelayedArray* subclass to a *DelayedArray*, as well as when and why this matters.
* Construct a *DelayedArray*:
  * From an in-memory array-like object.
  * From an on-disk data store (e.g., HDF5).
  * From scratch by writing data to a *RealizationSink*.

### What's out there already?

#### Learning goal

* Learn of existing functions and packages for constructing and computing on DelayedArray objects, avoiding the need to re-invent the wheel.

## Incoporating DelayedArray into a package

### Writing algorithms to process *DelayedArray* instances

#### Learning goals

* Learn common design patterns for writing performant code that operates on a DelayedArray.
* Evaluate whether an existing function that operates on an ordinary array can be readily adapted to work on a DelayedArray.
* Reason about potential bottlenecks in algorithms operating on DelayedArray objects.

#### Learning objectives

* Take a function that operates on rows or columns of a matrix and apply it to a DelayedMatrix.
* Use block-processing on a *DelayedArray* to compute:
  * A univariate (scalar) summary statistic (e.g., `max()`).
  * A multivariate (vector) summary statistic (e.g., `colSum()` or `rowMean()`).
  * A multivariate (array-like) summary statistic (e.g., `rowRanks()`).
* Design an algorithm that imports data into a DelayedArray.

## Questions and discussion

This section will be updated to address questions and to summarise the discussion from the presentation of this workshop at BioC2018. 


# TODOs

- Use **BiocStyle**?
-  Show packages depend on one another, with HDF5Array as the root (i.e. explain the HDF5 stack)
- Use `suppressPackageStartupMessages()` or equivalent.
