```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
    comment = "#>",
    collapse = TRUE,
    cache = TRUE
)
```
```{r include=FALSE, cache=FALSE}
knitr::opts_chunk$set(
    comment = "#>",
    collapse = TRUE,
    cache = TRUE
)
```
---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Effectively using the DelayedArray framework to support the analysis of large datasets

Authors:
    Peter Francis Hickey^[Department of Biostatistics, Johns Hopkins University],
    <br/>
Last modified: 12 June, 2018.

## Overview

### Description

This workshop will teach the fundamental concepts underlying the DelayedArray framework and related infrastructure. 
It is intended for package developers who want to learn how to use the DelayedArray framework to support the analysis of large datasets, particularly through the use of on-disk data storage.
The first part of the workshop will provide an overview of the DelayedArray 
infrastructure and introduce computing on DelayedArray objects using delayed operations and block-processing.
The second part of the workshop will present strategies for adding support for DelayedArray to an existing package and extending the DelayedArray framework.
Students can expect a mixture of lecture and question-and-answer session to teach the fundamental concepts.
There will be plenty of examples to illustrate common design patterns for writing performant code, although we will not be writing much code during the workshop.

### Pre-requisites

* Solid understanding of R
* Familiarity with common operations on arrays (e.g., `colSums()` and those available in the matrixStats package)
* Familiarity with object oriented programming, particularly S4, will be useful but is not essential
* No familiarity required of technical details of particular data storage backends (e.g., HDF5, sparse matrices)
* No familiarity required of particular biological techniques (e.g., single-cell RNA-seq)

### Participation

Questions and discussion are encouraged! 
This will be especially important to guide the second half of the worshop which focuses on integrating DelayedArray into an existing or new Bioconductor package.
Students will be expected to be able to follow and reason about example R code. 

### _R_ / _Bioconductor_ packages used

* DelayedArray
* HDF5Array
* SummarizedExperiment
* DelayedMatrixStats
* beachmat

### Time outline

| Activity                                          | Time |
|---------------------------------------------------|------|
| Introductory slides                               | 15m  |
| Part 1: Overview of DelayedArray framework        | 45m  |
| Part 2: Incoporating DelayedArray into a package  | 45m  |
| Questions and discussion                          | 15m  |

### Workshop goals and objectives

### Learning goals

* Identify when it is useful to use a DelayedArray instead of an ordinary array or other array-like data structure.
* Become familiar with the fundamental concepts of delayed operations, block-processing, and realization.
* Learn of existing functions and packages for constructing and computing on DelayedArray objects, avoiding the need to re-invent the wheel.
* Learn common design patterns for writing performant code that operates on a DelayedArray.
* Evaluate whether an existing function that operates on an ordinary array can be readily adapted to work on a DelayedArray.
* Reason about potential bottlenecks in algorithms operating on DelayedArray objects.

### Learning objectives

* Understand the differences between a DelayedArray instance and an instance of a subclass (e.g., HDF5Array, RleArray).
* Know what types of operations 'degrade' an instance of a DelayedArray subclass to a DelayedArray, as well as when and why this matters.
* Construct a DelayedArray:
  * From an in-memory array-like object.
  * From an on-disk data store (e.g., HDF5).
  * From scratch by writing data to a RealizationSink.
* Take a function that operates on rows or columns of a matrix and apply it to a DelayedMatrix.
* Use block-processing on a DelayedArray to compute:
  * A univariate (scalar) summary statistic (e.g., `max()`).
  * A multivariate (vector) summary statistic (e.g., `colSum()` or `rowMean()`).
  * A multivariate (array-like) summary statistic (e.g., `rowRanks()`).
* Design an algorithm that imports data into a DelayedArray.

## Introductory slides

Data from a high-throughput biological assay, such as single-cell RNA-sequencing (scRNA-seq), will often be summarised as a matrix of counts, where rows correspond to features and columns to samples^[Higher-dimensional arrays may be appropriate for some types of assays.].
Within **Bioconductor**, the *SummarizedExperiment* class is the recommended 
container for such data, offering a rich interface that tightly links assay measurements to data on the features and the samples.

![The _SummarizedExperiment_ class is used to store rectangular arrays of experimental results (_assays_). Although each _assay_ is here drawn as a matrix, higher-dimensional arrays are also supported.](https://docs.google.com/feeds/download/drawings/Export?id=1kiC8Qlo1mhSnLDqkGiRNPSo6GWn3C2duBszCFbJCB-g&exportFormat=svg)

The assay data are typically stored **in-memory** as ordinary _matrix_ or _array_ objects. 
The requirement that the data be stored in-memory becomes a real pain with the ever-growing size of 'omics datasets; it is now not uncommon to collect $10,000-100,000,000$ measurements on $100 - 1,000,000$ samples, which 
would occupy $10-1,000$ gigabytes (GB) if stored in-memory as ordinary R arrays!
**TABLE** (**TODO**: Link to table) gives some examples of contemporary experiments and the memory requirements if these data are to be stored in-memory as ordinary R arrays.

```{r, echo = FALSE}
# TODO: Add WGBS (mCA)
# TODO: An example of an RleArray-type dataset
x <- data.frame(
    Assay = c("scRNA-seq", "WGBS (mCG)"),
    Size = c(
        as.character(
            memuse::howbig(27998, 1306127, type = "integer", prefix = "SI")),
        as.character(
            2 * memuse::howbig(29307073, 145, type = "integer", prefix = "SI") + 
                memuse::howbig(29307073, 145, type = "double", prefix = "SI"))),
    "`nrow`" = c("27,998", "29,307,073"),
    "`ncol`" = c("1,306,127", "145"),
    "Number of assays" = c(1, 3),
    Type = c("sparse integer", "2 x dense integer, 1 x dense double"),
    Reference = c(
        "https://bioconductor.org/packages/TENxBrainData/", 
        "eGTEx (unpublished)"),
    check.names = FALSE,
    stringsAsFactors = FALSE)
# TODO: Manually update order to be increasing in x$Size
knitr::kable(x[2:1, ], row.names = FALSE)
```

There are various strategies for handling such data in R. 
For example,

- Sparse data
- Rle-like data
- Storing data on disk

- One option that is generally applicable is to keep the data on disk and not bring into memory until required. 
- This workshop will introduce you to the _DelayedArray_ framework.

### Motivation

- 'Omics data commonly represented as a matrix or higher-dimensional array
    - Tidy but not "tidy"
- In BioC, we use and love the _SummarizedExperiment_ container, where rows are features and columns are samples
- 'Omics data are forever getting larger
    - scRNA-seq on 10,000-1,000,000 cells
    - WGBS on 10-100s of samples
    - WGS on 10,000-1,000,000 of samples
- Want something array-like that scales to these large datasets
- Enter **DelayedArray**

## Overview of DelayedArray framework

## Incoporating DelayedArray into a package

## Questions and discussion

This section will be updated to address questions and to summarise the discussion from the presentation of this workshop at BioC2018. 

